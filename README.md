# Direction-of-arrival-estimation-using-deep-neural-network-for-hearing-aid-applications-using-smartphone
 
## Overview

This GitHub repository provides for Deep Neural Network based Two Microphone DOA estimation on Android smartphone platform. The example app provided here is for hearing improvement studies. 
> **Abstract:** Deep neural network (DNN) techniques are gaining popularity due to performance boost in many applications. In this work we propose a DNN-based method for finding the direction of arrival (DOA) of speech source for hearing study improvement and hearing aid applications using popular smartphone with no external components as a cost-effective stand-alone platform. We consider the DOA estimation as a classification problem and use the magnitude and phase of speech signal as a feature set for DNN training stage and obtaining appropriate model. The model is trained and derived using real speech and real noisy speech data recorded on smartphone in different noisy environments under low signal to noise ratios (SNRs). The DNN-based DOA method with the pre-trained model is implemented and run on Android smartphone in real time. The performance of proposed method is evaluated objectively and subjectively in the both training and unseen environments. The test results are presented showing the superior performance of proposed method over conventional methods.

You can find the manuscript for this GitHub repository :https://asa.scitation.org/doi/10.1121/2.0001256

## Audio-Video Demo

## Users Guides

A [User's Guide](Users-Guide-Android_TwoMicDOA_version_2.pdf) is provided describing the real-time implementation on Android smartphone platforms.

## Requirements 

- Pixel 1 smartphone and Android 9(API 28.0.3)

## License and Citation

The codes are licensed under open-source MIT license.

For any utilization of the code content of this repository, one of the following books needs to get cited by the user:

A.Küçük, I. Panahi, "Direction of arrival estimation using deep neural network for hearing aid applications using smartphone", Proceedings of Meetings on Acoustics, 178 ASA. Vol. 39. No. 1. ASA, 2019. 

## Disclaimer

- This work was supported in part by the National Institute of the Deafness and Other Communication Disorders (NIDCD) of the National Institutes of Health (NIH) under Award 1R01DC015430-04. The content is solely the responsibility of the authors and does not necessarily represent the official views of the NIH.
- The information and materials contained in this website is a presentation of the documented research work carried out by the faculty, students and personnel at the University of Texas at Dallas (UTD). This website including its content is available for public access with the understanding that UTD and the authorized faculty and students contributing to this website make no warranties, either expressed or implied, concerning the completeness, reliability, or suitability of the presented materials for any kind of applications. Neither UTD nor any contributor to this website and its content shall be held liable to any party for any use or misuse of the information and materials contained in this website in any form or shape. Nor does the UTD warrant that the use of this website information is free of any claims of copyright infringement. This website does not endorse any commercial providers or their products. UTD and faculty managing this website reserve the right to remove, update, alter, or take down any and all posted materials on this website at any time without notice.
